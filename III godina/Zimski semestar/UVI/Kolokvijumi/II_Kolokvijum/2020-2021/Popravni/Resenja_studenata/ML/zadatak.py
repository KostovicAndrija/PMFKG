import numpy as np
import pandas as pd
import seaborn as sns
# –£—á–∏—Ç–∞—Ç–∏ —Å–µ—Ç –ø–æ–¥–∞—Ç–∫–∞ diamonds.csv
data = pd.read_csv('diamonds.csv')
df = data.copy()

# –ü—Ä–æ–≤–µ—Ä–∏—Ç–∏ –¥–∞ –ª–∏ –Ω–µ–∫–µ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏ –ø–æ–¥–∞—Ç–∞–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—ò—É. 
# –£–∫–æ–ª–∏–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—ò–µ –¥–µ–æ –ø–æ–¥–∞—Ç–∞–∫–∞,–ø–æ–ø—É–Ω–∏—Ç–∏ –ø—Ä–æ—Å–µ—á–Ω–∏–º 
# –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏–º–∞ –∑–∞ —Ç–∞—ò —Ç–∏–ø –ø–æ–¥–∞—Ç–∞–∫–∞
df.isnull().sum()

# –ß–∏—Å—Ç–æ—õ—É –¥–∏—ò–∞–º–∞–Ω—Ç–∞ –∫–æ–¥–∏—Ä–∞—Ç–∏ –º–µ—Ç–æ–¥–æ–º Label Encoding, 
# –∞ –ø—Ä–µ–æ—Å—Ç–∞–ª–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—ò—Å–∫–µ –≤–∞—Ä–∏—ò–∞–±–ª–µ
# –∫–æ–¥–∏—Ä–∞—Ç–∏ –º–µ—Ç–æ–¥–æ–º One-Hot-Encoding
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['clarity'] = encoder.fit_transform(df['clarity'])
df.columns

categories = df.select_dtypes(include=['object']).columns
categories
df = pd.get_dummies(df, columns = categories, prefix=categories)
df.columns

# –ü–æ–¥–µ–ª–∏—Ç–∏ –ø–æ–¥–∞—Ç–∫–µ –Ω–∞ —Å–∫—É–ø –∑–∞ –æ–±—É–∫—É –∏ —Å–∫—É–ø –∑–∞ —Ç–µ—Å—Ç–∏—Ä–∞—ö–µ —É –æ–¥–Ω–æ—Å—É 70:30
from sklearn.model_selection import train_test_split
x = df.loc[:, df.columns != 'price'].values
y = df.loc[:, 'price'].values
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=50, shuffle=True)

""" 
    –ö—Ä–µ–∏—Ä–∞—Ç–∏ –∏ –æ–±—É—á–∏—Ç–∏ –º–æ–¥–µ–ª–µ –≤–∏—à–µ—Å—Ç—Ä—É–∫–µ –ª–∏–Ω–µ–∞—Ä–Ω–µ —Ä–µ–≥—Ä–µ—Å–∏—ò–µ –∏ 
    –≤–µ—à—Ç–∞—á–∫–µ –Ω–µ—É—Ä–æ–Ω—Å–∫–µ –º—Ä–µ–∂–µ.
    ANN –º–æ–¥–µ–ª —Å–∞–¥—Ä–∂–∏ 2 —Å–∫—Ä–∏–≤–µ–Ω–∞ —Å–ª–æ—ò–∞ —Å–∞ –ø–æ 5 –Ω–µ—É—Ä–æ–Ω–∞.
"""
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x_train, y_train)
y_lr_pred = regressor.predict(x_test)

from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)
nn_regressor = MLPRegressor(hidden_layer_sizes=(5,5), max_iter=50)
nn_regressor.fit(x_train, y_train.ravel())
y_nn_pred = nn_regressor.predict(x_test)

# –ò–∑–≤—Ä—à–∏—Ç–∏ –ø—Ä–µ–¥–∏–∫—Ü–∏—ò–µ –Ω–∞ —Ç–µ—Å—Ç–Ω–æ–º —Å–∫—É–ø—É.
df_lin = pd.DataFrame({'Actual': y_test, 'Predicted': y_lr_pred})
df_lin.head()

df_nn = pd.DataFrame({'Actual': y_test, 'Predicted': y_nn_pred})
df_nn.head()

# –ü–æ—Ç–æ–º –æ–¥—Ä–µ–¥–∏—Ç–∏ –º–µ—Ç—Ä–∏–∫–µ –æ–±–∞ –º–æ–¥–µ–ª–∞ –Ω–∞ —Ç–µ—Å—Ç–Ω–æ–º —Å–∫—É–ø—É MAE i RMSE 
from sklearn.metrics import mean_absolute_error, mean_squared_error
mae_lr = mean_absolute_error(y_test, y_lr_pred)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_lr_pred))
print("MAE LR : ", mae_lr)
print("RMSE LR : ", rmse_lr)

mae_nn = mean_absolute_error(y_test, y_nn_pred)
rmse_nn = np.sqrt(mean_squared_error(y_test, y_nn_pred))
print("MAE NN : ", mae_nn)
print("RMSE NN : ", rmse_nn)

"""
–ó–∞ –º–æ–¥–µ–ª —Å–∞ –º–∞—ö–æ–º –≥—Ä–µ—à–∫–æ–º –ú–ê–ï –Ω–∞—Ü—Ä—Ç–∞—Ç–∏ –¥–∏—ò–∞–≥—Ä–∞–º —Ä–∞—Å–ø—Ä—à–µ–Ω–æ—Å—Ç–∏. 
–ù–∞ ùë• –æ—Å–∏ –Ω–∞–ª–∞–∑–µ —Å–µ —Å—Ç–≤–∞—Ä–Ω–µ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏, –∞ –Ω–∞ ùë¶ –æ—Å–∏ –Ω–∞–ª–∞–∑–µ —Å–µ –ø—Ä–∏–¥–∏–∫–æ–≤–∞–Ω–µ 
–≤—Ä–µ–¥–Ω–æ—Å—Ç–∏. –ò—Å—Ü—Ä—Ç–∞—Ç–∏ –ø—Ä–∞–≤—É ùë¶ = ùë• –Ω–∞–∏—Å—Ç–æ–º –≥—Ä–∞—Ñ–∏–∫—É.
"""
import matplotlib.pyplot as plt
plt.scatter(y_test, y_nn_pred,  color='gray')
plt.plot(y_test, y_test, color='red', linewidth=2)
plt.show()